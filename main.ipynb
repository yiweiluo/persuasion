{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37f3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, json\n",
    "import pickle, dill\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37f567b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(528531, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtree_root_id</th>\n",
       "      <th>subtree_leaf_id</th>\n",
       "      <th>entry_order</th>\n",
       "      <th>degree_back_and_forth</th>\n",
       "      <th>convo_delta_pct</th>\n",
       "      <th>won_delta</th>\n",
       "      <th>convo_id</th>\n",
       "      <th>len</th>\n",
       "      <th>path_root_to_leaf</th>\n",
       "      <th>filtered_path_root_to_leaf</th>\n",
       "      <th>guid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t1_e45llf2</td>\n",
       "      <td>t1_e476c6z</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_973yb1</td>\n",
       "      <td>190.25</td>\n",
       "      <td>[t1_e45llf2, t1_e45mtzr, t1_e45p1ij, t1_e45pmfu, t1_e45q2fr, t1_e45qn42, t1_e46iqqp, t1_e476c6z]</td>\n",
       "      <td>[t1_e45llf2, t1_e45mtzr, t1_e45p1ij, t1_e45pmfu, t1_e45q2fr, t1_e45qn42, t1_e46iqqp, t1_e476c6z]</td>\n",
       "      <td>t1_e45llf2 | t1_e476c6z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t1_e45lq41</td>\n",
       "      <td>t1_e45o2sv</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_973yb1</td>\n",
       "      <td>125.25</td>\n",
       "      <td>[t1_e45lq41, t1_e45n24e, t1_e45nh0b, t1_e45o2sv]</td>\n",
       "      <td>[t1_e45lq41, t1_e45n24e, t1_e45nh0b, t1_e45o2sv]</td>\n",
       "      <td>t1_e45lq41 | t1_e45o2sv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t1_e45llf2</td>\n",
       "      <td>t1_e47qnva</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_973yb1</td>\n",
       "      <td>135.60</td>\n",
       "      <td>[t1_e45llf2, t1_e45mtzr, t1_e45p1ij, t1_e45pmfu, t1_e45q2fr, t1_e45qn42, t1_e465cee, t1_e471v3w, t1_e47m16x, t1_e47qnva]</td>\n",
       "      <td>[t1_e45llf2, t1_e45mtzr, t1_e45p1ij, t1_e45pmfu, t1_e45q2fr, t1_e45qn42, t1_e465cee, t1_e471v3w, t1_e47m16x, t1_e47qnva]</td>\n",
       "      <td>t1_e45llf2 | t1_e47qnva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_e45n34c</td>\n",
       "      <td>t1_e45ntcf</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_973yb1</td>\n",
       "      <td>213.50</td>\n",
       "      <td>[t1_e45n34c, t1_e45ntcf]</td>\n",
       "      <td>[t1_e45n34c, t1_e45ntcf]</td>\n",
       "      <td>t1_e45n34c | t1_e45ntcf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t1_e45l4gy</td>\n",
       "      <td>t1_e475ebc</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_973yb1</td>\n",
       "      <td>83.25</td>\n",
       "      <td>[t1_e45l4gy, t1_e45m7si, t1_e46gi63, t1_e475ebc]</td>\n",
       "      <td>[t1_e45l4gy, t1_e45m7si, t1_e46gi63, t1_e475ebc]</td>\n",
       "      <td>t1_e45l4gy | t1_e475ebc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subtree_root_id subtree_leaf_id  entry_order  degree_back_and_forth  \\\n",
       "0      t1_e45llf2      t1_e476c6z           19                      2   \n",
       "1      t1_e45lq41      t1_e45o2sv           20                      3   \n",
       "2      t1_e45llf2      t1_e47qnva           19                      2   \n",
       "3      t1_e45n34c      t1_e45ntcf           27                      2   \n",
       "4      t1_e45l4gy      t1_e475ebc           15                      2   \n",
       "\n",
       "   convo_delta_pct  won_delta   convo_id     len  \\\n",
       "0         0.052632          1  t3_973yb1  190.25   \n",
       "1         0.052632          1  t3_973yb1  125.25   \n",
       "2         0.052632          1  t3_973yb1  135.60   \n",
       "3         0.052632          1  t3_973yb1  213.50   \n",
       "4         0.052632          1  t3_973yb1   83.25   \n",
       "\n",
       "                                                                                                          path_root_to_leaf  \\\n",
       "0                          [t1_e45llf2, t1_e45mtzr, t1_e45p1ij, t1_e45pmfu, t1_e45q2fr, t1_e45qn42, t1_e46iqqp, t1_e476c6z]   \n",
       "1                                                                          [t1_e45lq41, t1_e45n24e, t1_e45nh0b, t1_e45o2sv]   \n",
       "2  [t1_e45llf2, t1_e45mtzr, t1_e45p1ij, t1_e45pmfu, t1_e45q2fr, t1_e45qn42, t1_e465cee, t1_e471v3w, t1_e47m16x, t1_e47qnva]   \n",
       "3                                                                                                  [t1_e45n34c, t1_e45ntcf]   \n",
       "4                                                                          [t1_e45l4gy, t1_e45m7si, t1_e46gi63, t1_e475ebc]   \n",
       "\n",
       "                                                                                                 filtered_path_root_to_leaf  \\\n",
       "0                          [t1_e45llf2, t1_e45mtzr, t1_e45p1ij, t1_e45pmfu, t1_e45q2fr, t1_e45qn42, t1_e46iqqp, t1_e476c6z]   \n",
       "1                                                                          [t1_e45lq41, t1_e45n24e, t1_e45nh0b, t1_e45o2sv]   \n",
       "2  [t1_e45llf2, t1_e45mtzr, t1_e45p1ij, t1_e45pmfu, t1_e45q2fr, t1_e45qn42, t1_e465cee, t1_e471v3w, t1_e47m16x, t1_e47qnva]   \n",
       "3                                                                                                  [t1_e45n34c, t1_e45ntcf]   \n",
       "4                                                                          [t1_e45l4gy, t1_e45m7si, t1_e46gi63, t1_e475ebc]   \n",
       "\n",
       "                      guid  \n",
       "0  t1_e45llf2 | t1_e476c6z  \n",
       "1  t1_e45lq41 | t1_e45o2sv  \n",
       "2  t1_e45llf2 | t1_e47qnva  \n",
       "3  t1_e45n34c | t1_e45ntcf  \n",
       "4  t1_e45l4gy | t1_e475ebc  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load argument paths dataframe\n",
    "per_path_df = pd.read_csv('per_path_df.csv')\n",
    "for col in ['path_root_to_leaf','filtered_path_root_to_leaf']:\n",
    "    per_path_df[col] = per_path_df[col].apply(lambda x: json.loads(x))\n",
    "print(per_path_df.shape)\n",
    "display(per_path_df.head())\n",
    "#per_path_df.loc[0]['filtered_path_root_to_leaf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c45b2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(407, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lexicon category</th>\n",
       "      <th>arguments</th>\n",
       "      <th>polysemous</th>\n",
       "      <th>exclude for polysemy?</th>\n",
       "      <th>PA</th>\n",
       "      <th>IA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>call up</td>\n",
       "      <td>remember</td>\n",
       "      <td>dobj</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>remember</td>\n",
       "      <td>cc</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recollect</td>\n",
       "      <td>remember</td>\n",
       "      <td>dobj</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remember</td>\n",
       "      <td>remember</td>\n",
       "      <td>cc</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>think back</td>\n",
       "      <td>remember</td>\n",
       "      <td>pobj</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>think of</td>\n",
       "      <td>remember</td>\n",
       "      <td>dobj</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>leave off</td>\n",
       "      <td>forget/err</td>\n",
       "      <td>dobj</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>misunderstand</td>\n",
       "      <td>forget/err</td>\n",
       "      <td>dobj</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>omit</td>\n",
       "      <td>forget/err</td>\n",
       "      <td>dobj</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>miss</td>\n",
       "      <td>forget/err</td>\n",
       "      <td>dobj</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word lexicon category arguments polysemous exclude for polysemy?  \\\n",
       "0        call up         remember      dobj          n                   NaN   \n",
       "1         recall         remember        cc          n                   NaN   \n",
       "2      recollect         remember      dobj          n                   NaN   \n",
       "3       remember         remember        cc          n                   NaN   \n",
       "4     think back         remember      pobj          n                   NaN   \n",
       "5       think of         remember      dobj          n                   NaN   \n",
       "6      leave off       forget/err      dobj          n                   NaN   \n",
       "7  misunderstand       forget/err      dobj          n                   NaN   \n",
       "8           omit       forget/err      dobj          n                   NaN   \n",
       "9           miss       forget/err      dobj          n                   NaN   \n",
       "\n",
       "      PA    IA  \n",
       "0   high  neut  \n",
       "1    NaN   NaN  \n",
       "2    NaN   NaN  \n",
       "3    NaN   NaN  \n",
       "4    NaN   NaN  \n",
       "5    NaN   NaN  \n",
       "6  other  high  \n",
       "7    NaN   NaN  \n",
       "8    NaN   NaN  \n",
       "9    NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "think                       23\n",
      "argue                       21\n",
      "say                         19\n",
      "predict                     19\n",
      "be_shown                    18\n",
      "arrive                      18\n",
      "claim                       17\n",
      "show                        16\n",
      "mention                     16\n",
      "arrive_via_reasoning        16\n",
      "advance                     15\n",
      "reason                      13\n",
      "forget/err                  12\n",
      "declare                     11\n",
      "deny                        11\n",
      "repeat                      11\n",
      "advise                      10\n",
      "affirm                       9\n",
      "predict_sci                  9\n",
      "concede                      8\n",
      "explain_sci                  8\n",
      "show_tentative               8\n",
      "show_hidden                  8\n",
      "promise                      7\n",
      "high_commitment              7\n",
      "agree                        7\n",
      "doubt                        7\n",
      "express                      7\n",
      "emphasize                    7\n",
      "imply                        7\n",
      "remember                     6\n",
      "predict_tentative            6\n",
      "understand                   6\n",
      "other_emotive                5\n",
      "respond                      5\n",
      "pretend                      5\n",
      "other_manner                 4\n",
      "high_commitment_no_basis     4\n",
      "other                        1\n",
      "Name: lexicon category, dtype: int64\n",
      "\n",
      "Found 25 MWE predicates.\n",
      "['call up' 'think back' 'think of' 'leave off' 'leave out' 'make believe'\n",
      " 'cry out' 'agree with' 'disagree with' 'talk about' 'bring up'\n",
      " 'pass along' 'allude to' 'touch on' 'react to' 'make known' 'spell out'\n",
      " 'let on' 'mull over' 'work out' 'work out' 'point out' 'put forward'\n",
      " 'get wind' 'find out' 'get word']\n"
     ]
    }
   ],
   "source": [
    "# Load predicate lexicons\n",
    "my_lexicon_df = pd.read_csv('my_predicate_lexicons.csv')\n",
    "my_lexicon_df = my_lexicon_df[['word','lexicon category','arguments','polysemous','exclude for polysemy?','PA','IA']]\n",
    "lexicon_cat_annots = my_lexicon_df.loc[(~pd.isnull(my_lexicon_df['PA'])) & \n",
    "                                       (~pd.isnull(my_lexicon_df['IA']))].copy()\n",
    "lexicon_cat2PA = dict(zip(lexicon_cat_annots['lexicon category'], lexicon_cat_annots['PA']))\n",
    "lexicon_cat2IA = dict(zip(lexicon_cat_annots['lexicon category'], lexicon_cat_annots['IA']))\n",
    "\n",
    "my_lexicon_df = my_lexicon_df.loc[my_lexicon_df['exclude for polysemy?']!='y'].copy()\n",
    "print(my_lexicon_df.shape)\n",
    "display(my_lexicon_df.head(10))\n",
    "print(my_lexicon_df['lexicon category'].value_counts())\n",
    "preds_set = set(my_lexicon_df['word'].values)\n",
    "\n",
    "mwe_preds = my_lexicon_df.loc[my_lexicon_df['word'].apply(lambda x: len(x.split( )) > 1)]['word'].values\n",
    "mwe_preds_set = set(mwe_preds)\n",
    "print(f'\\nFound {len(mwe_preds_set)} MWE predicates.')\n",
    "print(mwe_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e830199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subj_pred_category_counts(path_guid, subj_set, pred_set, \n",
    "                                  subj_pred_tups_per_subtree=subj_pred_tups_per_subtree,\n",
    "                                  verbose=False):\n",
    "    \"\"\"\n",
    "    Counts the number of occurrences of a (subj, pred) combination within an argument path.\n",
    "    Example usage: \n",
    "        `get_subj_pred_category_counts('t1_e45l4gy | t1_e475ebc', {'you'}, WORD_CATEGORIES['concessive']`.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_subj_pred_tups = subj_pred_tups_per_subtree[path_guid]\n",
    "    \n",
    "    if len(subj_set) == 1:\n",
    "        in_category_tups = [x for x in all_subj_pred_tups\n",
    "                            if (len(x['pred_neg']['text']) == 0) \n",
    "                            and (len(x['pred_q']['text'])==0) \n",
    "                            and (len(x['pred_cond']['text'])==0) \n",
    "                            and (x['in_quote']==False) \n",
    "                            and (len(set(x['pred_modal']['lemma']).intersection(disallowed_modals)) == 0) \n",
    "                            and (x['main_subj']['text'] is not None) \n",
    "                            and ((x['main_subj']['lemma'].lower() in subj_set) \n",
    "                                or (x['main_subj']['text'].lower() in subj_set))\n",
    "                                #or (len(set(x['subj_mods']['lemma']).intersection(subj_set)) > 0))\n",
    "                            and x['main_pred']['lemma'][0] in pred_set]\n",
    "    else:\n",
    "        in_category_tups = [x for x in all_subj_pred_tups\n",
    "                            if (len(x['pred_neg']['text']) == 0) \n",
    "                            and (len(x['pred_q']['text'])==0) \n",
    "                            and (len(x['pred_cond']['text'])==0) \n",
    "                            and (x['in_quote']==False) \n",
    "                            and (len(set(x['pred_modal']['lemma']).intersection(disallowed_modals)) == 0) \n",
    "                            and (x['main_subj']['text'] is not None) \n",
    "                            and ((x['main_subj']['lemma'].lower() in subj_set) \n",
    "                                or (x['main_subj']['text'].lower() in subj_set)\n",
    "                                or (len(set([l.lower() for l in x['subj_mods']['lemma']]).intersection(subj_set)) > 0))\n",
    "                            and x['main_pred']['lemma'][0] in pred_set]\n",
    "    if verbose:\n",
    "        print(in_category_tups)\n",
    "    return len(in_category_tups) # excludes negation, quotes, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
